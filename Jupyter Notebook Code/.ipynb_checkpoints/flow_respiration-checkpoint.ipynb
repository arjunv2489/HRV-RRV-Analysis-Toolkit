{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis for Flow channel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import mne\n",
    "import heartpy as hp\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import butter, freqs, filtfilt, find_peaks\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing .edf File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"../NewData/BINDUV~ PSG_9e1a1e68-ac02-4a80-89a4-cdea20ea282a.edf\"\n",
    "data = mne.io.read_raw_edf(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting data from the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = data.get_data()\n",
    "info = data.info\n",
    "\n",
    "# Un-comment the below code to view the data fields\n",
    "\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Un-comment the below code to view the data channels\n",
    "\n",
    "# print(data.ch_names)\n",
    "data_channel = data.ch_names\n",
    "\n",
    "j = 0\n",
    "for i in data_channel:\n",
    "    print(i , \"     \" , j)\n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Selected Required Channel: \", data.ch_names[25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow = raw_data[25]    # Print the data from Flow channel\n",
    "print(flow)\n",
    "flow = flow[200000:1100000]\n",
    "# Better list containing data\n",
    "# Un-comment the below code for viewing the flow channel data\n",
    "\n",
    "# for i in flow:\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering flow signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Butter Worth Filter\n",
    "fs = 256\n",
    "fc = 0.5\n",
    "b, a = butter(6, fc/(fs/2), 'low', analog=False)\n",
    "\n",
    "# Filtering the signal\n",
    "y = filtfilt(b, a, flow)\n",
    "\n",
    "peaks, _ = find_peaks(y, distance = 150, height=0.0001)\n",
    "# peaks, _ = find_peaks(y, distance = 150, height=)\n",
    "peaks_num = (len(peaks))                             # Contains the total no. of peaks\n",
    "plt.plot(y, 'b-', linewidth = 1)\n",
    "plt.plot(peaks, y[peaks], \"*\", color=\"red\")          # Plotting the peak points\n",
    "# fig1 = plt.gfc()\n",
    "plt.show()                                           # Plotting the flow channel data\n",
    "\n",
    "\n",
    "n = len(flow)\n",
    "new_var = len(peaks)\n",
    "\n",
    "\n",
    "# print(n)\n",
    "duration_sec = n / fs\n",
    "duration_min = duration_sec / 60\n",
    "\n",
    "\n",
    "avg = new_var / duration_min\n",
    "\n",
    "print(\"Beats per minute: \", round(avg))\n",
    "print(\"Number of spikes per minute: \", round(peaks_num, 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_peak_interval = []\n",
    "inter_peak_interval_index = []\n",
    "\n",
    "for i in range(0, len(y[peaks]) - 1):\n",
    "    inter_peak_interval.append(y[peaks][i + 1] - y[peaks][i])\n",
    "    inter_peak_interval_index.append(i)\n",
    "    \n",
    "ipi_mean = np.array(inter_peak_interval).mean()\n",
    "print('Peak interval Average: ', ipi_mean)\n",
    "\n",
    "\n",
    "plt.plot(inter_peak_interval_index, inter_peak_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peak Interval Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_peak_time = []\n",
    "\n",
    "for i in range(0, len(y[peaks]) - 1):\n",
    "    inter_peak_time.append(((peaks[i+1] - peaks[i]))/fs)\n",
    "    \n",
    "    \n",
    "ipt_mean = np.array(inter_peak_time).mean()\n",
    "ipt_max = np.array(inter_peak_time).max()\n",
    "ipt_min = np.array(inter_peak_time).min()\n",
    "# print(inter_peak_time)\n",
    "\n",
    "# print(peaks)\n",
    "print('Peak Interval Time average: ', round(ipt_mean, 2))\n",
    "print('Peak Interval Time Max: ', round(ipt_max, 2))\n",
    "print('Peak Interval Time Min: ', round(ipt_min, 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Peak Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# peak_time = []\n",
    "# for i in range(0, len(peaks)):\n",
    "#     peak_time.append((peaks[i] / 256))\n",
    "\n",
    "# avg_peak = round(np.array(peak_time).mean())\n",
    "# print(\"Average Peak Time: \", avg_peak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index = []\n",
    "# for i in range(len(peaks)):\n",
    "#     if peaks[i]>= 1000000 and peaks[i]<=2000000:\n",
    "#         index.append(i)\n",
    "# # print(index)\n",
    "\n",
    "# peak_copy = y[peaks].copy()\n",
    "\n",
    "# begin = index[0]\n",
    "# end = index[-1]\n",
    "\n",
    "# print('Max',y[peaks][begin:end+1].max())\n",
    "# print('Min',y[peaks][begin:end+1].min())\n",
    "\n",
    "# max = y[peaks][begin:end+1].max()\n",
    "# min = y[peaks][begin:end+1].min()\n",
    "# outliers = []\n",
    "# outliers_index = []\n",
    "# for i in range(len(y[peaks])):\n",
    "# #     print(i)\n",
    "#     if y[peaks][i] > max :\n",
    "#         outliers.append(y[peaks])\n",
    "#         outliers_index.append(i)\n",
    "#         peak_copy[i] = max\n",
    "        \n",
    "        \n",
    "# print(len(outliers))\n",
    "# # print(outliers)\n",
    "# print(len(peaks))\n",
    "# print(peak_copy.max())\n",
    "\n",
    "# y[peaks] = peak_copy\n",
    "# print(y[peaks].max())\n",
    "# plt.plot(y, 'b-', linewidth=1)\n",
    "\n",
    "# plt.plot(peaks, peak_copy, \"*\", color=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Peak Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_mean= np.array(y[peaks]).mean()\n",
    "print(np.array(y[peaks]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt('data.csv', (peaks_num, flow_mean))\n",
    "\n",
    "\n",
    "df = pd.DataFrame([])\n",
    "data = [[file,len(flow),dur,round(peaks_num),bpm_avg,ipi_mean,avg_peak]]\n",
    "\n",
    "df1 = pd.DataFrame(data,columns=['File Name','Signal Length','Duration','Beat Count','BPM','Peak Interval Avg','Peak Time Avg'])\n",
    "df = df.append(df1,  ignore_index = True)\n",
    "print(df)\n",
    "df.to_csv(\"Stats_temp.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MultiFile Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "# import heartpy as hp\n",
    "from scipy.signal import butter, freqs, filtfilt\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "onlyfiles = [f for f in listdir(\"./dataset\") if isfile(join(\"./dataset\", f))]\n",
    "df = pd.DataFrame([])\n",
    "def find_time(sig):\n",
    "    time = ((sig/256)/60)/60\n",
    "    print(\"Time: \", time , \"\\nLength: \",sig)\n",
    "    return ((sig/256)/60)/60\n",
    "\n",
    "\n",
    "def channel_id(channel, val):   \n",
    "    j =0\n",
    "    for i in channel:\n",
    "        if(i == val):\n",
    "            return j\n",
    "        \n",
    "        j+=1\n",
    "        \n",
    "current = 1\n",
    "total = len(onlyfiles)\n",
    "for file in onlyfiles:\n",
    "    filename = file\n",
    "    file = join(\"./dataset\", file)\n",
    "    print(\"Processing..\", file, current,\"/\",total)\n",
    "    data = mne.io.read_raw_edf(file)\n",
    "    raw_data = data.get_data()\n",
    "    # you can get the metadata included in the file and a list of all channels:\n",
    "    info = data.info\n",
    "    channels = data.ch_names\n",
    "    sig = raw_data[channel_id(channels,'FLOW')]\n",
    "    \n",
    "    #   print(\"Signal Loaded..\")\n",
    "    fs = 256\n",
    "    n = len(sig)\n",
    "    # n = 1000\n",
    "    fc = 4\n",
    "    duration_sec = n / fs\n",
    "    duration_min = duration_sec / 60\n",
    "\n",
    "    b, a = butter(6, fc/(fs/2), 'low', analog=False)\n",
    "    # w, h = freqs(b, a)\n",
    "\n",
    "    y = filtfilt(b, a, sig[:])\n",
    "\n",
    "    peaks, _ = find_peaks(y, distance = 150, height=0)\n",
    "    plt.plot(y, 'b-', linewidth=1)\n",
    "    plt.plot(peaks, y[peaks], \"*\", color=\"red\")\n",
    "    fig1 = plt.gcf()\n",
    "    plt.show()\n",
    "\n",
    "        \n",
    "    #     fig1.savefig(file.split(\".\")[0]+\".png\", dpi= 100)\n",
    "    beat_count = len(peaks)\n",
    "    fs = 256\n",
    "    n = len(sig)\n",
    "    duration_sec = n/fs\n",
    "    duration_min = duration_sec/60\n",
    "    bpm_avg = beat_count/duration_min\n",
    "    print(bpm_avg)\n",
    "    \n",
    "    inter_peak_interval = []\n",
    "    inter_peak_interval_index = []\n",
    "\n",
    "    for i in range(0, len(y[peaks]) - 1):\n",
    "        inter_peak_interval.append(y[peaks][i + 1] - y[peaks][i])\n",
    "        inter_peak_interval_index.append(i)\n",
    "\n",
    "    ipi_mean = np.array(inter_peak_interval).mean()\n",
    "    print('Peak interval Average: ', ipi_mean)\n",
    "\n",
    "    plt.plot(inter_peak_interval_index, inter_peak_interval)\n",
    "    \n",
    "    inter_peak_time = []\n",
    "\n",
    "    for i in range(0, len(y[peaks]) - 1):\n",
    "        inter_peak_time.append(((peaks[i+1] - peaks[i]))/60)\n",
    "\n",
    "\n",
    "    ipt_mean = np.array(inter_peak_time).mean()\n",
    "    ipt_max = np.array(inter_peak_time).max()\n",
    "    ipt_min = np.array(inter_peak_time).min()\n",
    "    # print(inter_peak_time)\n",
    "\n",
    "    # print(peaks)\n",
    "    print('Peak Interval Time average: ',ipt_mean)\n",
    "    print('Peak Interval Time Max: ',ipt_max)\n",
    "    print('Peak Interval Time Min: ',ipt_min)\n",
    "    \n",
    "    data = [[file,find_time(len(sig)),bpm_avg,ipi_mean,ipt_max,ipt_min,avg_peak, np.array(y[peaks]).mean()]]\n",
    "    current+=1\n",
    "    df1 = pd.DataFrame(data,columns=['File Name','Duration','BPM','Peak Interval Avg','Peak Time Interval Max','Peak Time Interval Min','Peak Time Avg','Peak Avg'])\n",
    "    df = df.append(df1,  ignore_index = True)\n",
    "    print(df)\n",
    "\n",
    "\n",
    "df.to_csv(\"Flow.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
